{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raihanewubd/CSE457/blob/main/CSE_475_Lab_4_Ensembling_and_XAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensembling Approaches on Loan Approval Dataset\n",
        "\n",
        "**1. Introduction**\n",
        "\n",
        "In machine learning, ensemble methods are powerful techniques that combine the predictions of multiple models to improve accuracy, robustness, and generalization. By aggregating multiple models, ensemble methods reduce the variance and bias associated with individual models, leading to better predictive performance. Here, we’ll explore four popular ensembling methods:\n",
        "\n",
        "* Bagging (Bootstrap Aggregating): Bagging involves training multiple instances of the same model on different random subsets of the training data, then aggregating their predictions. A common example is the Random Forest model, where each tree is trained on a different subset of data. Bagging helps reduce variance, making it effective with models prone to overfitting, like decision trees.\n",
        "\n",
        "* Boosting: Boosting is an iterative process where each model learns from the errors of the previous ones. Boosting algorithms like Gradient Boosting and XGBoost give higher weights to misclassified instances, helping the ensemble focus on challenging samples. This technique improves accuracy by reducing bias, but it requires careful tuning to avoid overfitting.\n",
        "\n",
        "* Stacking: Stacking is an ensemble technique that uses multiple base models to make predictions and then combines these predictions with a \"meta-learner\" model. The meta-learner uses the predictions from the base models as input features, creating a layered structure. Stacking is useful for combining diverse models to capture different patterns in the data.\n",
        "\n",
        "* Voting: The voting ensemble method combines the predictions of multiple models by voting. In hard voting, each model votes for a class label, and the label with the most votes is selected. In soft voting, the predicted probabilities are averaged, and the class with the highest probability is chosen. Voting is particularly useful for stabilizing predictions when combining strong individual classifiers.\n",
        "\n",
        "**Explanation of the Dataset and Objective**\n",
        "\n",
        "The dataset, loan_data.csv, contains various features representing user load approval status, with a target variable indicating the class or outcome we're trying to predict. The objective of this analysis is to:\n",
        "\n",
        "* Use various ensembling techniques (Bagging, Boosting, Stacking, and Voting) to build predictive models on this dataset.\n",
        "* Compare model performances across these ensemble methods.\n",
        "* Fine-tune each model to optimize performance and gain insights into which ensembling technique works best for this dataset.\n",
        "* The goal is to determine which ensemble method provides the most accurate, generalizable model while interpreting feature importance and the decision-making process using XAI techniques, like SHAP, to enhance our\n",
        "understanding of model predictions."
      ],
      "metadata": {
        "id": "wON1h-g4_7S6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Dataset\n",
        "- Mobile Device Usage and User Behavior Dataset\n",
        "- Analyzing Mobile Usage Patterns and User Behavior Classification Across Devices\n",
        "- Dataset: https://www.kaggle.com/datasets/taweilo/loan-approval-classification-data"
      ],
      "metadata": {
        "id": "DiIrzLen6tvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**used to download a file from Google Drive directly in a Jupyter Notebook or Google Colab environment**"
      ],
      "metadata": {
        "id": "PJHA8kScGYaQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Libraries"
      ],
      "metadata": {
        "id": "bV7BER3PAobo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#These are popular ensemble methods used for classification (RandomForestClassifier, GradientBoostingClassifier)\n",
        "#This is an ensemble model that combines multiple classifiers to\n",
        "#improve prediction accuracy (VotingClassifier)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "\n",
        "#A simple and widely used\n",
        "#linear classifier, commonly used as a baseline in classification tasks.\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Used to standardize features by removing the mean and\n",
        "#scaling to unit variance, which improves model performance(StandardScaler)\n",
        "\n",
        "#Used to transform categorical data into a numerical format by encoding\n",
        "#categorical variables as binary (one-hot) vectors(OneHotEncoder)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "#A powerful tool for transforming specific columns in a dataframe,\n",
        "#often used to apply different preprocessing steps to numerical\n",
        "#and categorical columns.\n",
        "from sklearn.compose import ColumnTransformer\n"
      ],
      "metadata": {
        "id": "G-bm6hnc63cA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Dataset"
      ],
      "metadata": {
        "id": "crExr58AAtJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/loan_data.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "vxG_zzl_ArCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "- Handle missing values, if any.\n",
        "- Encode categorical variables.\n",
        "- Feature scaling (if necessary)"
      ],
      "metadata": {
        "id": "jhZpkXZOBK4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This code preprocesses a dataset by scaling numerical features, encoding categorical features, and combining both into a final processed DataFrame ready for supervised learning tasks.**"
      ],
      "metadata": {
        "id": "eQ2bnHDyNKZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['loan_status'], axis=1)\n",
        "print(X)\n",
        "#This operation reduces each class label by 1, assuming\n",
        "#class labels originally start from 1. If classes were\n",
        "#initially numbered as 1, 2, 3, etc., they’ll now be 0, 1, 2, etc.\n",
        "\n",
        "\n",
        "\n",
        "#Many machine learning algorithms in Python\n",
        "#(especially in libraries like scikit-learn)\n",
        "#expect class labels to start from 0. This\n",
        "#adjustment simplifies compatibility with\n",
        "#these algorithms and avoids indexing issues.\n",
        "# y = df['loan_status']-1\n",
        "y = df['loan_status']\n",
        "\n",
        "#Identifying Feature Types:\n",
        "\n",
        "# Split the features into categorical and numerical\n",
        "\n",
        "#Selects the columns containing categorical data\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "#Selects columns containing numerical data\n",
        "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "\n",
        "#Data Preprocessing:\n",
        "\n",
        "# Standard scaling for numerical features only\n",
        "\n",
        "#will adjust the data so that each feature has\n",
        "#a mean of 0 and a standard deviation of 1.\n",
        "scaler = StandardScaler()\n",
        "\n",
        "#first learns the mean and standard deviation for\n",
        "#each numerical feature in X.\n",
        "#This helps ensure that all numerical features are on a similar scale.\n",
        "\n",
        "#this process centers the data around zero and adjusts the scale,\n",
        "#which often improves the performance of machine learning models\n",
        "#by preventing any one feature from dominating due to its larger scale.\n",
        "scaled_numerical_data = scaler.fit_transform(X[numerical_features])\n",
        "\n",
        "# One-hot encoding for categorical features only\n",
        "\n",
        "#The OneHotEncoder converts categorical variables\n",
        "#into binary (one-hot) encoded variables.\n",
        "encoder = OneHotEncoder(drop='first')\n",
        "encoded_categorical_data = encoder.fit_transform(X[categorical_features])\n",
        "\n",
        "# Concatenate the scaled numerical and encoded categorical data\n",
        "\n",
        "#Concatenates the scaled numerical and encoded categorical arrays horizontally,\n",
        "#combining them into a single dataset.\n",
        "processed_data = np.hstack([scaled_numerical_data, encoded_categorical_data.toarray()])\n",
        "\n",
        "# Convert to DataFrame with appropriate column names\n",
        "final_columns = numerical_features.tolist() + encoder.get_feature_names_out(categorical_features).tolist()\n",
        "final_df = pd.DataFrame(processed_data, columns=final_columns)\n",
        "\n",
        "#Stores the preprocessed features in data_X for modeling\n",
        "data_X = final_df.copy()"
      ],
      "metadata": {
        "id": "NiRIUn-3BZNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''ya = df['loan_status']\n",
        "print(ya)'''"
      ],
      "metadata": {
        "id": "RWEe-uMfGxcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_X.head()"
      ],
      "metadata": {
        "id": "xxsPp708CTE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data_X\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "uxE4IKK1C3ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "D9LuOiHzC7yA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bagging Approach: Random Forest"
      ],
      "metadata": {
        "id": "A5-wQv7TDBCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest Classifier Initialization\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "#Training the Model\n",
        "rf_model.fit(X_train, y_train)\n",
        "#Making Predictions\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "#Evaluating the Model\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_pred))\n"
      ],
      "metadata": {
        "id": "4n3_7NeaCU0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boosting Approach: Gradient Boosting"
      ],
      "metadata": {
        "id": "mW01c6w3DFxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "gb_model.fit(X_train, y_train)\n",
        "gb_pred = gb_model.predict(X_test)\n",
        "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, gb_pred))\n"
      ],
      "metadata": {
        "id": "VpJeh2p-DDsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stacking Approach\n",
        "- Use a meta-classifier (e.g., Logistic Regression) on top of base learners"
      ],
      "metadata": {
        "id": "dUGpapQjDLrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "#The stacking model uses a list of base learners—Random Forest,\n",
        "#Gradient Boosting, and XGBoost classifiers—each with 100 estimators\n",
        "#and a fixed random state for reproducibility.\n",
        "\n",
        "# Define base models\n",
        "base_learners = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42)),\n",
        "    ('xgb', XGBClassifier(n_estimators=100, random_state=42))\n",
        "]\n",
        "\n",
        "# Define meta-learner\n",
        "\n",
        "# Logistic Regression is chosen as the meta-learner,\n",
        "#which combines the predictions from the base learners to make final predictions. The meta-learner is often a simpler model (e.g., Logistic Regression or Decision Tree)\n",
        "#that helps synthesize the information from the base models.\n",
        "meta_learner = LogisticRegression()\n",
        "\n",
        "# Set up the stacking model\n",
        "\n",
        "#This line initializes the stacking classifier,\n",
        "#which combines the base models and uses the meta-learner\n",
        "#for final predictions. Cross-validation (cv=5) is\n",
        "#used within the stacking process to improve robustness.\n",
        "stacking_model = StackingClassifier(estimators=base_learners, final_estimator=meta_learner, cv=5)\n",
        "\n",
        "stacking_model.fit(X_train, y_train)\n",
        "stacking_pred = stacking_model.predict(X_test)\n",
        "print(\"Stacking Model Accuracy:\", accuracy_score(y_test, stacking_pred))\n",
        "\n",
        "# Define meta-learner\n",
        "meta_learner = LogisticRegression()\n",
        "\n",
        "# Set up the stacking model\n",
        "stacking_model = StackingClassifier(estimators=base_learners, final_estimator=meta_learner, cv=2)\n",
        "stacking_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "UY7Qf71GDIDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **- Combine multiple classifiers by voting.**"
      ],
      "metadata": {
        "id": "Fdri0PAoDRos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This ensemble model combines several base models—Random Forest,\n",
        "#Gradient Boosting, and Support Vector Classifier (SVC)—to\n",
        "#make predictions. The voting='soft' parameter indicates that\n",
        "#the classifier will use the probabilities predicted by each model\n",
        "#and then average them to make final predictions.\n",
        "#This \"soft voting\" often yields better results when\n",
        "#the models provide probability estimates.\n",
        "\n",
        "\n",
        "vote_model = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "        ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42)),\n",
        "        ('svc', SVC(probability=True))\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n",
        "vote_model.fit(X_train, y_train)\n",
        "vote_pred = vote_model.predict(X_test)\n",
        "print(\"Voting Classifier Accuracy:\", accuracy_score(y_test, vote_pred))\n"
      ],
      "metadata": {
        "id": "MMxjs11bDPLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "- Compare the performance of all models.\n"
      ],
      "metadata": {
        "id": "fiMzqhhmDWVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Random Forest:\", accuracy_score(y_test, rf_pred))\n",
        "print(\"Gradient Boosting:\", accuracy_score(y_test, gb_pred))\n",
        "print(\"Stacking Model:\", accuracy_score(y_test, stacking_pred))\n",
        "print(\"Voting Classifier:\", accuracy_score(y_test, vote_pred))\n"
      ],
      "metadata": {
        "id": "vJZVY5g8DURe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross-Validation Performance Comparison\n",
        "* Use cross_val_score from sklearn.model_selection to perform cross-validation and evaluate each ensemble model's accuracy across folds.\n",
        "* Set cv=5 for 5-fold cross-validation (can be adjusted based on preference or dataset size)."
      ],
      "metadata": {
        "id": "4n_C_jGaDdzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Model Definitions:\n",
        "You define four models: Random Forest, Gradient Boosting, Stacking, and Voting.\n",
        "\n",
        "Each model is instantiated with specific configurations:\n",
        "\n",
        "Random Forest and Gradient Boosting are set up with 100 estimators.\n",
        "\n",
        "Stacking combines Random Forest and SVC, with Logistic Regression as the meta-learner.\n",
        "\n",
        "Voting combines Random Forest, Gradient Boosting, and SVC using soft voting (i.e., probability averaging)."
      ],
      "metadata": {
        "id": "5YxU0cW7QqBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "    \"Stacking\": StackingClassifier(\n",
        "        estimators=[\n",
        "            ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "            ('svc', SVC(probability=True))\n",
        "        ],\n",
        "        final_estimator=LogisticRegression()\n",
        "    ),\n",
        "    \"Voting\": VotingClassifier(\n",
        "        estimators=[\n",
        "            ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "            ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42)),\n",
        "            ('svc', SVC(probability=True))\n",
        "        ],\n",
        "        voting='soft'\n",
        "    )\n",
        "}\n",
        "\n",
        "# Perform cross-validation and store results\n",
        "\n",
        "#scores.mean() gives the average accuracy across all folds.\n",
        "#scores.std() provides the variability in accuracy between the folds.\n",
        "results = {}\n",
        "for model_name, model in models.items():\n",
        "    scores = cross_val_score(model, data_X, y, cv=2, scoring='accuracy')\n",
        "    results[model_name] = scores\n",
        "    print(f\"{model_name} Cross-Validation Accuracy: {scores.mean():.4f} ± {scores.std():.4f}\")\n"
      ],
      "metadata": {
        "id": "gJ-w0PDLDZ3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Visualizing Cross-Validation Results"
      ],
      "metadata": {
        "id": "QgMJgsTCD0o7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Prepare results for visualization\n",
        "import pandas as pd\n",
        "\n",
        "#converted into a pandas DataFrame (results_df).\n",
        "#This allows for easier manipulation and visualization.\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Plot box plot for model comparison\n",
        "plt.figure(figsize=(10, 6))\n",
        "results_df.boxplot()\n",
        "plt.title(\"Cross-Validation Accuracy Comparison of Ensemble Models\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "'''It seems that the box plot shows perfect accuracy across all models,\n",
        "leading to a flat line around 1.0. This could happen if the models are\n",
        "overfitting or the dataset is too simple.'''\n"
      ],
      "metadata": {
        "id": "Do6ibqe4Dksj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix for Each Model"
      ],
      "metadata": {
        "id": "lO4DcsLvD5rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fit each model on the training data and plot the confusion matrix for each\n",
        "for model_name, model in models.items():\n",
        "    # Fit the model and predict on test set\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "    plt.title(f\"Confusion Matrix for {model_name}\")\n",
        "    plt.xlabel(\"Predicted Labels\")\n",
        "    plt.ylabel(\"True Labels\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "M4Rll5M6D2rG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Precision and Recall for Each Model"
      ],
      "metadata": {
        "id": "3J0LqZSwEA-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Fit each model on the training data and calculate precision, recall, and F1-score\n",
        "for model_name, model in models.items():\n",
        "    # Fit the model and predict on test set\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate precision, recall, and F1-score\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    # Print the metrics\n",
        "    print(f\"{model_name} Performance Metrics:\")\n",
        "    print(f\" - Precision: {precision:.4f}\")\n",
        "    print(f\" - Recall: {recall:.4f}\")\n",
        "    print(f\" - F1 Score: {f1:.4f}\\n\")\n"
      ],
      "metadata": {
        "id": "YifXlU8LD7df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary of Metrics"
      ],
      "metadata": {
        "id": "stKDa39KEE9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect all metrics in a DataFrame for summary\n",
        "metrics_summary = []\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    metrics_summary.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1 Score\": f1\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame\n",
        "import pandas as pd\n",
        "metrics_df = pd.DataFrame(metrics_summary)\n",
        "\n",
        "# Display the summary\n",
        "print(\"Model Performance Summary:\")\n",
        "metrics_df"
      ],
      "metadata": {
        "id": "xu4HbSBhEC1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explainable AI (XAI)"
      ],
      "metadata": {
        "id": "5hE1hdplERp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explaining Model Predictions Using SHAP\n",
        "SHAP provides detailed insights into feature contributions for individual predictions and the overall model. We'll compute SHAP values for the Random Forest model as an example, but this approach can be extended to other models as well."
      ],
      "metadata": {
        "id": "6rKyNIssEUao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How SHAP Works with Different Ensemble Models**\n",
        "\n",
        "**Bagging Models (e.g., Random Forest)**\n",
        "\n",
        "For bagging models, SHAP’s TreeExplainer efficiently computes SHAP values across each tree in the ensemble, averaging feature contributions to provide both global and local interpretability. This is useful for understanding which features are consistently important across all trees in a Random Forest.\n",
        "\n",
        "**Boosting Models (e.g., Gradient Boosting, XGBoost)**\n",
        "\n",
        "Boosting models like XGBoost use sequential training, where each iteration corrects the mistakes of the previous model. SHAP’s explanations reveal how feature importance evolves over iterations, highlighting which features the model focuses on as it learns. SHAP also captures the impact of feature interactions within the model’s complex structure.\n",
        "\n",
        "**Stacking Models**\n",
        "\n",
        "In stacking, where multiple base models feed into a meta-learner, SHAP can explain the contribution of each base model's predictions to the final outcome. Additionally, SHAP can be applied to each base model individually, revealing how each model uses features to make predictions, and how the meta-learner combines these predictions.\n",
        "\n",
        "**Voting Classifier**\n",
        "\n",
        "Although SHAP cannot directly interpret the aggregated predictions in a voting classifier, it can explain each base model individually, helping to understand how each model contributes to the ensemble’s overall decision. By comparing SHAP values across models, you can see how each one votes differently for features and identify potential model disagreements."
      ],
      "metadata": {
        "id": "mFBb21nUG5x5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "# Use a subset of the data for SHAP to reduce computation time\n",
        "\n",
        "#This code uses SHAP to explain the predictions of the Random Forest model\n",
        "#on a subset of the test data.\n",
        "X_sample = X_test.sample(100, random_state=42)\n",
        "\n",
        "\n",
        "# Initialize SHAP explainer for the Random Forest model\n",
        "\n",
        "#This initializes a TreeExplainer for the Random Forest model. The TreeExplainer is efficient\n",
        "#for tree-based models (like Random Forest) and computes SHAP values to explain the output of\n",
        "#individual predictions.\n",
        "explainer = shap.TreeExplainer(models[\"Random Forest\"])\n",
        "\n",
        "#This computes the SHAP values for each feature in the sample data.\n",
        "#The SHAP values represent how much each feature contributes to the difference between the prediction\n",
        "#and the expected output (mean prediction).\n",
        "shap_values = explainer.shap_values(X_sample)"
      ],
      "metadata": {
        "id": "WLia-zrfCbTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **illustrates the feature importance in terms of the average impact each feature has on the model's predictions**"
      ],
      "metadata": {
        "id": "xxFk9yO5VkkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Calculate mean absolute SHAP values across all classes for each feature\n",
        "\n",
        "#This step calculates the mean absolute SHAP value for each feature.\n",
        "\n",
        "#The shap_values array contains the SHAP values for all instances in X_sample,\n",
        "#and by taking the absolute value and averaging across all instances, we get\n",
        "#an overall measure of each feature's contribution to the model's predictions.\n",
        "\n",
        "mean_shap_values = np.mean([np.abs(sv) for sv in shap_values], axis=0)  # Resulting shape should be (100, 12) to match X_sample\n",
        "\n",
        "# If mean_shap_values is (12, 5), take the mean across classes, resulting in a vector (12, )\n",
        "\n",
        "#If there are multiple classes (for multi-class classification), this line computes the mean\n",
        "#SHAP value across all classes, collapsing the results to a single value for each feature.\n",
        "\n",
        "mean_shap_values = np.mean(mean_shap_values, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "# Repeat this vector to create a matrix that matches X_sample's shape\n",
        "\n",
        "#This step repeats the mean_shap_values for each row in the sample data.\n",
        "#This is necessary to create a shape that matches the original X_sample for visualization.\n",
        "mean_shap_values_repeated = np.tile(mean_shap_values, (X_sample.shape[0], 1))\n",
        "\n",
        "\n",
        "# Plot the summary plot with the repeated matrix\n",
        "shap.summary_plot(mean_shap_values_repeated, X_sample, plot_type=\"bar\", feature_names=X_sample.columns)\n"
      ],
      "metadata": {
        "id": "lPWJR20aGSU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explaining Model Predictions Using LIME"
      ],
      "metadata": {
        "id": "Rkh9ykE4EnqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime"
      ],
      "metadata": {
        "id": "Nzd84BKoCeqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LIME's LimeTabularExplainer provides a simple way to explain individual predictions of a model by approximating it locally with an interpretable model, highlighting the most influential features for that prediction.**"
      ],
      "metadata": {
        "id": "b_6cwkHhWf5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "\n",
        "# Initialize the LIME explainer\n",
        "lime_explainer = LimeTabularExplainer(X_train.values, feature_names=data_X.columns, class_names=y.values, mode='classification')\n",
        "\n",
        "# Choose a sample from the test set to explain\n",
        "sample_index = 0 # Adjust to analyze a different sample\n",
        "\n",
        "#Generate the Explanation\n",
        "#This generates a local explanation for the chosen test instance using the Random Forest model’s predicted probabilities\n",
        "\n",
        "exp = lime_explainer.explain_instance(X_test.values[sample_index], models[\"Random Forest\"].predict_proba, num_features=10)\n",
        "print(X_test.values[sample_index])\n",
        "# Display the explanation\n",
        "exp.show_in_notebook()\n",
        "exp.show_in_notebook(show_table=True, show_all=False)\n"
      ],
      "metadata": {
        "id": "Bs6UiJwVEXiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "import numpy as np\n",
        "\n",
        "# Choose a valid sample index\n",
        "sample_index = 6  # Replace with a valid index, or use np.random.randint(0, len(X_test))\n",
        "\n",
        "\n",
        "# Ensure feature_names and class_names are valid strings\n",
        "feature_names = final_columns\n",
        "\n",
        "# Ensure that class names in LIME are ordered the same way as the model output\n",
        "class_names = [str(cls) for cls in sorted(y.unique())]  # Sorting the class labels to ensure correct order\n",
        "\n",
        "# Initialize the LIME explainer with the corrected class names\n",
        "lime_explainer = LimeTabularExplainer(\n",
        "    X_train.values,\n",
        "    feature_names=feature_names,\n",
        "    class_names=class_names,\n",
        "    mode='classification'\n",
        ")\n",
        "\n",
        "# Generate the explanation again\n",
        "exp = lime_explainer.explain_instance(\n",
        "    X_test.values[sample_index],\n",
        "    models[\"Random Forest\"].predict_proba,\n",
        "    num_features=10\n",
        ")\n",
        "\n",
        "# Display the explanation\n",
        "exp.show_in_notebook(show_table=True, show_all=False)\n",
        "\n",
        "# Print the selected sample's feature values\n",
        "print(\"\\n\\nFeature values of the selected sample:\")\n",
        "print(X_test.values[sample_index])\n",
        "\n",
        "# Get the actual class of the selected sample\n",
        "actual_class = y_test.values[sample_index]\n",
        "print(f\"Actual class: {actual_class}\")\n",
        "\n",
        "# Get the predicted class of the selected sample\n",
        "predicted_class = models[\"Random Forest\"].predict(X_test.values[sample_index].reshape(1, -1))[0]\n",
        "print(f\"Predicted class: {predicted_class}\")\n",
        "\n",
        "# Get the predicted probabilities of the selected sample\n",
        "predicted_probabilities = models[\"Random Forest\"].predict_proba(X_test.values[sample_index].reshape(1, -1))[0]\n",
        "print(f\"Predicted probabilities: {predicted_probabilities}\")\n"
      ],
      "metadata": {
        "id": "yWbbs58rX79_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Positive or negative contributions of each feature to the predicted class\n",
        "\n",
        "#(e.g., Battery Drain (mAh/day) has a high positive impact)."
      ],
      "metadata": {
        "id": "Xwil9uHREqse"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}